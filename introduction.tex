\section{Introduction}\label{intro}\sloppy
The availability of data and vast cloud-based computational resources has ushered in an era of more sophisticated machine learning (ML) models in prediction, recommendation, and automation.
The database community has built systems to support almost every stage of the development process including featurization~\cite{keystone,zhang2014mat}, distributed model training~\cite{hellerstein2012madlib, crotty2014tupleware, feng2012towards, tensor}, and model deployment~\cite{crankshawmissing}.  
However, an under-served, yet crucial, component is the management and cleaning of dirty data. 
 If unaccounted for, this dirty data can drastically bias predictions that are undesirable or even dangerous~\cite{vanderbilt2012let}.  Recent papers and surveys of analysts suggest that such problems are pervasive~\cite{sculley2014machine,kandel2012,krishnan2016hilda}.

As a concrete example, we are collaborating with a data science company called \company\footnote{Anonymized at the request of the company.} that ranks sales leads based on Salesforce.com data on past sales leads, and additional information scraped from the web about the client.
The company predicts the probability of viability for a potential (unlabeled) lead.
The data are acquired from a combination of manual data entry and automatically scraped web sources, and thus, inconsistencies, missing data, and incorrect values are a significant problem.  For instance, a typical error is the inconsistent representation of missing values (e.g., ``-999'', ``EMPTY'' or ``none'' may be used depending on the sales representative).  If the featurization code does not recognize and address these errors, it can lead to biases that degrade the quality of the model. For example, the data scientist may impute a default mean value for all blank attributes but miss the code ``-999'', which is then interpreted as a semantic value. 
Detecting and repairing all such errors is extremely time-consuming, and for every new client this effort will have to be repeated.

This company's data cleaning challenges are not unique and are prevalent in many industrial ML pipelines~\cite{krishnan2016hilda}.  
Software Engineers write custom conditional cleaning scripts that are a combination of a {\it detector}, which are a collection of Boolean functions that specify a subset of records that are dirty, and {\it repair} functions that transform or delete those records.  It is not enough to write these scripts once.
The predictive nature of ML applications means that the system will continuously encounter and process new, unseen data.
Software Engineers must constantly monitor and maintain the data processing pipeline to account for unexpected changes~\cite{sculley2014machine, DBLP:conf/sigmod/KrishnanFGWW16}.
To further exacerbate this problem, modern prediction models rely on data integrated from a wide variety of sources (e.g., \company combines on average 5-10 sources to train a model).  For each data source, the engineer must understand domain-specific information (e.g., invariants) in order to accurately clean the data.  For instance, we found that each machine learning dataset required between $1-7$ custom error detection rules in order to identify the low-hanging errors in those datasets.

To reduce this burden, we present a new system, called \sys, that automates the process of detecting and repairing a common class of data errors called {\it domain value violations} that occur when an attribute value is outside of its value domain.  Numerous data quality surveys across the database, statistics, and scientific literature highlight the prevalence, variety, and importance of this class of errors, which include missing data, incorrect data, or inconsistent representations of the same logical data value~\cite{muller2005problems,li2010improving,kim2003taxonomy,kandel2011research}.  \sys focuses on this common class of errors, and leaves more complex scenarios such as entity resolution to the Software Engineers. After deployment, \sys can help ensure that deployed models maintain high accuracy even in the presence of incoming dirty data, and engineers are only needed to address drastic changes to the input data. 

In traditional relational data cleaning, it is very hard to quantify the accuracy of an automatic data cleaning process without ground truth--a dataset where {\it all attributes are fully correct}.
On the other hand, in ML, cleanly labeled test data is often available (e.g., the results of following a sales lead). 
Labels often represent directly observed phenomena making them relatively clean, while features are often weaker signals integrated from multiple disparate sources and subject to error and frequent change.
This allows us to define accuracy in terms of the model's predictive accuracy--the data cleaning being a means to improving that predictive accuracy.
In this sense, our goal is not to fully clean each record and recover a consistent relation; instead, to utilize the available cleaning resources to best improve a model trained on this dataset.
The key challenge is to efficiently search the space of possible conditional data cleaning scripts (detector and repair combinations) while ensuring that the model does not overfit~\cite{DBLP:journals/pvldb/KrishnanWWFG16,krishnan2016hilda}.   

Our primary observation is that a conditional cleaning script can be interpreted as generating a new set of features (the cleaned values), and thereby generating a new model trained on those cleaned features. 
We can view the process of selecting the best sequence of cleaning operations as an ensembling problem, i.e., selecting the best collection models that collectively estimate a label. 
Although there are many possible algorithms~\cite{dietterich2000ensemble}, we use a powerful technique called Boosting~\cite{freund1995desicion} that composes a set of weak learners into a strong learner.  
First, unlike methods that are specific to certain classes of models (e.g., linear models, differentiable models), boosting can be applied to black-box models. 
Second, it takes interactions and correlations between the different data cleaning models into account by incrementally selecting ``orthogonal'' compositions.


\sys takes as input a relational table, a library of detector functions $\mathcal{D}$ that generate (possibly incorrect) predicates that match candidate dirty records, a library of repair functions $\mathcal{F}$ that transform or delete a record, and a user-specified classifier training procedure \texttt{train()}.
\sys has two key components: an automatic error detector to determine subsets of records that are dirty, and a repair selector to select repair actions for those dirty records using boosting.
We cast the former component into a featurization problem so that the user focuses on the familiar task of creating feature extraction functions while \sys translates these features into error detection rules using a technique called Isolation Forests~\cite{liu2008isolation}.  Further, we have written a general set of featurizers, including one that is a novel adaptation of the \textsf{word2vec} neural network architecture that is effective at detecting multi-attribute errors.  The neural network can be individually tailored to each dataset and learn to predict the co-occurrence of attributes in a record. 
The detectors output relational predicates $p_i$, which can be used to detect candidate errors.  The second component then uses boosting to generate a sequence of conditional cleaning scripts $(p_i, r_i)$ to be applied to the training and test datasets, where $r_i$ is the repair function to be applied to records matching predicate $p_i$.

This paper focuses on data errors that cause domain value violations in the context of supervised classification models (both single and multi-class).  The system is currently designed for a single-node setting. Our contributions are as follows:

\vspace{0.25em}\noindent\textbf{Cleaning as Boosting: } We present a new automated data cleaning system based on statistical boosting that finds the best ensemble of operations from a library of operations to maximize the predictive performance of a downstream model. 

\stitle{Automatic Model Improvements:} We evaluated \sys on 12 datasets collected from Kaggle, the UCI repository, real-world data analyses, and \company, and improved absolute prediction accuracy by up to $9\%$ in comparison to baseline (non-ensembled integrity constraint+quantitative outlier detector) approaches on completely unseen test data. 

\vspace{0.5em}\noindent\textbf{Error Detection Library: } We have built an optimized library of data cleaning operations based on deterministic rules and statistical criteria from which \sys selects. To better detect errors in categorical attributes, we developed a novel detector based on the \textsf{Word2Vec} neural network architecture. Following prior experimental procedures~\cite{DBLP:journals/pvldb/AbedjanCDFIOPST16}, the library achieves a detection accuracy of 81\% of all of the errors found by hand-written rules on eight machine learning datasets.  %\sys is on average 40\% more accurate than applying statistical outlier detection to only the quantitative attributes.

\vspace{0.5em}\noindent\textbf{Optimizations: } Our optimizations including parallelism, materialization, and indexing techniques show a $22.2\times$ end-to-end speedup on a 16-core machine.

% and indexing-based optimizations speed up the boosting and repair selection  We demonstrate how we can parallelize the inner-loop of the boosting operation, and on a 16-core machine \sys achieves a 9.7x speedup for the repair selection step. Similarly, we show that building an index can speed up operator selection .






\iffalse
The problem of dirty training data in ML is subtle as most learning algorithms are robust to statistical noise.
However, un-modeled systematic biases in the training data can still adversely affect the results~\cite{DBLP:journals/pvldb/KrishnanWWFG16, DBLP:conf/case/MahlerKLSMKPWFAG14, xiaofeature}.
The way that the developer chooses to address corruption will have a significant impact on the performance of the ML application.
Consider a music recommender system where a recent software update causes songs longer than 5 minutes to have ``NULL'' ratings.
If the ML developer treats a NULL rating as ``0 stars'', those songs may never get recommended.
To avoid this bias, it may be more prudent to discard those ratings or impute a default  value (e.g., mean over all previous non-NULL ratings).

To setup the abstract search problem, we are given a dataset $R$, a library of data cleaning operations $\mathcal{L}=\{l_1,...,l_k\}$, a user-specified model training program which returns a classifier, and an oracle that evaluates the prediction accuracy of the classifier (e.g., a ground truth clean test dataset).
Our objective is to find a classifier that maximizes prediction accuracy by applying compositions of operators in our library to $R$ and training on the resulting dataset.
While this problem is inherently combinatorial, the key insight is to model the hypothesis testing procedure as a form of adaptive statistical boosting. 
\fi




%The datasets are inconsistent in the way they represent missing information (e.g., some numerical fields left blank, some fields with a placeholder value of ``-999''). 
%Featurization code that does not recognize that a blank attribute value is semantically equivalent to a ``-999'' attribute value can lead to biases--for example, the data scientist may impute a sensible default mean value for all of the blank attributes but treat the ``-999'' as the given value.

\if{0}
Clearly, some level of automation in detecting and handling erroneous data can reduce the burden on data scientists.
Automated rule-based data repair is a well-studied field~\cite{DBLP:conf/sigmod/ChuIKW16}, but the ML setting presents additional challenges and structure that are important to understand.
In ML, incoming records are, in a sense, both data (during training) and queries (during prediction).
This provides additional degrees-of-freedom in handling dirty data.
For example, when asked to predict a label for a dirty example, one may want to return a ``fail-safe'' prediction instead of cleaning it first and then asking for a prediction.
Second, ML applications often have a way of measuring prediction accuracy.
Labels often represent directly observed user-behavior (e.g., sale vs. no sale, whether the user clicked a link etc.), and thus, are relatively consistent over the lifetime of an application.
On the other hand, the features used to predict the labels may be integrated from a variety of different company databases and susceptible to inconsistencies and change.
With this in mind, we present \sys, a new data cleaning system that detects errors in ML data and uses knowledge of the labels to adaptively select from a set of repair actions to maximize prediction accuracy.
\fi